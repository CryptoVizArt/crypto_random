{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-14T02:22:04.204070Z",
     "start_time": "2024-11-14T02:22:04.202627Z"
    }
   },
   "source": [
    ""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T02:22:07.986857Z",
     "start_time": "2024-11-14T02:22:04.204967Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Base URL for historical snapshots\n",
    "base_url = \"https://coinmarketcap.com/historical/\"\n",
    "\n",
    "# List of dates to scrape, you could make this dynamic based on available dates in base_url\n",
    "dates = [\"20130428\", \"20130505\", \"20130512\"]  # Add more dates in the format 'YYYYMMDD'\n",
    "\n",
    "# Prepare an empty list to store data\n",
    "all_data = []\n",
    "\n",
    "# Loop through each date\n",
    "for date in dates:\n",
    "    url = f\"{base_url}{date}/\"\n",
    "    print(f\"Scraping {url}\")\n",
    "    \n",
    "    # Send request to get page content\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to retrieve data for {date}\")\n",
    "        continue\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    # Find the table or div containing asset data (check HTML structure of each snapshot page)\n",
    "    rows = soup.select(\"table tbody tr\")  # Modify selector as per actual structure\n",
    "    \n",
    "    # Loop through the rows and extract the top 125 assets\n",
    "    for i, row in enumerate(rows[:125]):  # Limit to top 125 rows\n",
    "        try:\n",
    "            symbol = row.select_one(\".cmc-table__cell--sort-by__symbol\").text.strip()\n",
    "            market_cap = row.select_one(\".cmc-table__cell--sort-by__market-cap\").text.strip()\n",
    "            \n",
    "            # Append to the all_data list\n",
    "            all_data.append({\n",
    "                \"Date\": date,\n",
    "                \"Rank\": i + 1,\n",
    "                \"Symbol\": symbol,\n",
    "                \"MarketCap\": market_cap\n",
    "            })\n",
    "        except AttributeError:\n",
    "            print(f\"Missing data for rank {i + 1} on date {date}\")\n",
    "    \n",
    "    # Delay to avoid hitting the server too fast\n",
    "    time.sleep(1)  # Adjust as needed\n",
    "\n",
    "# Convert to DataFrame and save to CSV\n",
    "df = pd.DataFrame(all_data)\n",
    "df.to_csv(\"coinmarketcap_historical_data.csv\", index=False)\n",
    "print(\"Data saved to coinmarketcap_historical_data.csv\")"
   ],
   "id": "8b17998028c2c704",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping https://coinmarketcap.com/historical/20130428/\n",
      "Scraping https://coinmarketcap.com/historical/20130505/\n",
      "Scraping https://coinmarketcap.com/historical/20130512/\n",
      "Data saved to coinmarketcap_historical_data.csv\n"
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
